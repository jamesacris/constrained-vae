{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# First, configure GPU  #\n",
    "#########################\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using TensorFlow v2.4.1\n"
     ]
    }
   ],
   "source": [
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# check version\n",
    "print('Using TensorFlow v%s' % tf.__version__)\n",
    "acc_str = 'accuracy' if tf.__version__[:2] == '2.' else 'acc'\n",
    "\n",
    "# helpers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "# need certainty to explain some of the results\n",
    "import random as python_random\n",
    "python_random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "# %load_ext tensorboard\n",
    "import datetime\n",
    "import os\n",
    "logs_base_dir = \"./constrained_tensorboard_logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "log_dir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of training data: 60000\nNumber of test data: 10000\nImage pixels: (28, 28)\nNumber of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# normalise images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# create a dataset (iterable) from the data using a specified batch size\n",
    "batch_size = 128\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# print info\n",
    "print(\"Number of training data: %d\" % len(train_labels))\n",
    "print(\"Number of test data: %d\" % len(test_labels))\n",
    "print(\"Image pixels: %s\" % str(train_images[0].shape))\n",
    "print(\"Number of classes: %d\" % (np.max(train_labels) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"encoder\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 28, 28, 8)    136         input_1[0][0]                    \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 14, 14, 8)    0           conv2d[0][0]                     \n__________________________________________________________________________________________________\nbatch_normalization (BatchNorma (None, 14, 14, 8)    32          max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 14, 14, 8)    584         batch_normalization[0][0]        \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 7, 7, 8)      0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 7, 7, 8)      32          max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nflatten (Flatten)               (None, 392)          0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 2)            786         flatten[0][0]                    \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 2)            786         flatten[0][0]                    \n__________________________________________________________________________________________________\nsampling (Sampling)             (None, 2)            0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 2,356\nTrainable params: 2,324\nNon-trainable params: 32\n__________________________________________________________________________________________________\nModel: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 2)]               0         \n_________________________________________________________________\ndense (Dense)                (None, 16)                48        \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               2176      \n_________________________________________________________________\ndense_2 (Dense)              (None, 784)               101136    \n_________________________________________________________________\nreshape (Reshape)            (None, 28, 28)            0         \n=================================================================\nTotal params: 103,360\nTrainable params: 103,360\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sampling z with (z_mean, z_log_var)\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "# latent dimension\n",
    "latent_dim = 2\n",
    "\n",
    "# build the encoder (convolutional layers)\n",
    "image_input = keras.Input(shape=(28, 28, 1))\n",
    "# x = layers.Flatten()(image_input)\n",
    "# x = layers.Dense(128, activation='relu')(x)\n",
    "# x = layers.Dense(16, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(8, kernel_size=(4, 4), activation=\"relu\", padding=\"same\")(image_input)\n",
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Flatten()(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z_output = Sampling()([z_mean, z_log_var])\n",
    "encoder_VAE = keras.Model(image_input, [z_mean, z_log_var, z_output], name=\"encoder\")\n",
    "encoder_VAE.summary()\n",
    "\n",
    "\n",
    "# build the decoder (dense layers)\n",
    "z_input = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(16, activation=\"relu\")(z_input)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
    "image_output = layers.Reshape((28, 28))(x)\n",
    "decoder_VAE = keras.Model(z_input, image_output, name=\"decoder\")\n",
    "decoder_VAE.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BVAE class\n",
    "class BVAE(keras.Model):\n",
    "    # constructor\n",
    "    # remove beta, add in warmup, d, gamma, lr_lambda, lr_w\n",
    "    def __init__(self, encoder, decoder, KLD_aim, **kwargs): \n",
    "        super(BVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        # self.warmup = warmup\n",
    "        # self.d = d\n",
    "        self.KLD_aim = KLD_aim\n",
    "        # self.gamma = gamma\n",
    "        # self.lr_init_lambda = lr_init_lambda\n",
    "        # self.lr_w = lr_w\n",
    "\n",
    "\n",
    "    # customise train_step() to implement constrained optimisation\n",
    "    # \n",
    "    # The goal is to optimise the dual of the problem: min reconstr_loss\n",
    "    # subject to KLD <= some value.\n",
    "    # \n",
    "    # The dual is: (max over lambda)(min over w) Lagrangian.\n",
    "    # Lagrangian = reconstr_loss + lambda*h(w),\n",
    "    # h(w) = [sum over training examples of ReLU(KLD - KLD_aim)]\n",
    "    # def train_step(self, x):\n",
    "    #     if isinstance(x, tuple):\n",
    "    #         x = x[0]\n",
    "        \n",
    "    #     Lambda = 0\n",
    "\n",
    "    #     for i in range(warmup): # will this actually iterate? Perhaps need to look into writing custom training loop.\n",
    "    #         ####################################\n",
    "    #         # SGD step for reconstruction loss #\n",
    "    #         ####################################\n",
    "    #         with tf.GradientTape() as tape:\n",
    "    #             # encoding\n",
    "    #             z_mean, z_log_var, z = self.encoder(x)\n",
    "    #             # decoding\n",
    "    #             x_prime = self.decoder(z)\n",
    "    #             # reconstruction error by binary crossentropy loss\n",
    "    #             reconstruction_loss = (\n",
    "    #                 tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * 28 * 28\n",
    "    #             )\n",
    "    #             # KL divergence\n",
    "    #             kld = -0.5 * tf.reduce_mean(\n",
    "    #                 1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "    #             )\n",
    "    #             # constraint h\n",
    "    #             h = tf.nn.relu(kld - KLD_aim)\n",
    "    #             # Lagrangian\n",
    "    #             lagrangian = reconstruction_loss + Lambda * h\n",
    "    #         # apply gradient\n",
    "    #         grads = tape.gradient(lagrangian, self.trainable_weights)\n",
    "    #         self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "    #         # return loss for metrics log\n",
    "    #         return {\n",
    "    #             \"loss\": loss,\n",
    "    #             \"reconstruction_loss\": reconstruction_loss,\n",
    "    #             \"kld\": kld,\n",
    "    #         }\n",
    "        \n",
    "    #     l = 1\n",
    "    #     t = 1\n",
    "    #     t1 = 1\n",
    "    #     lr_lambda = self.lr_init_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "KLD_aim = 1.0\n",
    "# Change these to adjust learning rates\n",
    "# lr_lambda = 0.01\n",
    "# lr_w = 0.001\n",
    "\n",
    "# N.B. Look this up for learning rate decay:\n",
    "# tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "#     initial_learning_rate, decay_steps, decay_rate, staircase=False, name=None\n",
    "# )\n",
    "\n",
    "# build the BVAE\n",
    "vae_model = BVAE(encoder=encoder_VAE, decoder=decoder_VAE, KLD_aim=KLD_aim)\n",
    "\n",
    "# compile the VAE\n",
    "vae_model.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lagrangian loss functions & derivative wrt lambda\n",
    "def lagrangian(reconstr_loss, kld, Lambda):\n",
    "    # constraint h\n",
    "    h = tf.nn.relu(kld - KLD_aim)\n",
    "    # Lagrangian\n",
    "    l = reconstr_loss + Lambda * h\n",
    "    return tf.reduce_mean(l)\n",
    "\n",
    "def dL_dlambda(kld):\n",
    "    # constraint h\n",
    "    h = tf.nn.relu(kld - KLD_aim)\n",
    "    # derivative = h\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# Train steps for custom loop #\n",
    "###############################\n",
    "\n",
    "# Warmup training step (this is just train_w_step with lambda = 0)\n",
    "@tf.function\n",
    "def warmup_step(x):\n",
    "    if isinstance(x, tuple):\n",
    "        x = x[0]\n",
    "    with tf.GradientTape() as tape:\n",
    "        # encoding\n",
    "        z_mean, z_log_var, z = vae_model.encoder(x)\n",
    "        # decoding\n",
    "        x_prime = vae_model.decoder(z)\n",
    "        # reconstruction error by binary crossentropy loss\n",
    "        reconstruction_loss = (\n",
    "            tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * 28 * 28\n",
    "        )\n",
    "        loss = reconstruction_loss # optimise for reconstruction loss only\n",
    "    # apply gradient\n",
    "    grads = tape.gradient(loss, vae_model.trainable_weights)\n",
    "    vae_model.optimizer.apply_gradients(zip(grads, vae_model.trainable_weights))\n",
    "\n",
    "    # metrics log\n",
    "    logits = {\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "    return logits\n",
    "\n",
    "# Reconstruction training step (updates model params)\n",
    "@tf.function\n",
    "def train_w_step(x, Lambda):\n",
    "    if isinstance(x, tuple):\n",
    "        x = x[0]\n",
    "    with tf.GradientTape() as tape:\n",
    "        # encoding\n",
    "        z_mean, z_log_var, z = vae_model.encoder(x)\n",
    "        # decoding\n",
    "        x_prime = vae_model.decoder(z)\n",
    "        # reconstruction error by binary crossentropy loss\n",
    "        reconstruction_loss = (\n",
    "            tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * 28 * 28\n",
    "        )\n",
    "        # KL divergence\n",
    "        kld = -0.5 * tf.reduce_mean(\n",
    "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "        )\n",
    "        # loss = lagrangian\n",
    "        loss = lagrangian(reconstruction_loss, kld, Lambda)\n",
    "    # apply gradient\n",
    "    grads = tape.gradient(loss, vae_model.trainable_weights)\n",
    "    vae_model.optimizer.apply_gradients(zip(grads, vae_model.trainable_weights))\n",
    "\n",
    "    # metrics log\n",
    "    logits = {\n",
    "        \"loss\": loss,\n",
    "        \"reconstruction_loss\": reconstruction_loss,\n",
    "        \"kl_loss\": kld,\n",
    "        \"lambda\": Lambda,\n",
    "    }\n",
    "    return logits\n",
    "\n",
    "# Constraint training step (updates lambda)\n",
    "# @tf.function\n",
    "def train_lambda_step(x, lr, Lambda):\n",
    "    if isinstance(x, tuple):\n",
    "        x = x[0]\n",
    "    \n",
    "    # with tf.GradientTape() as tape:\n",
    "    # encoding\n",
    "    z_mean, z_log_var, z = vae_model.encoder(x)\n",
    "    # decoding\n",
    "    # x_prime = vae_model.decoder(z)\n",
    "    # reconstruction error by binary crossentropy loss\n",
    "    # reconstruction_loss = (\n",
    "    #     tf.reduce_mean(keras.losses.binary_crossentropy(x, x_prime)) * 28 * 28\n",
    "    # )\n",
    "    # KL divergence\n",
    "    kld = -0.5 * tf.reduce_mean(\n",
    "        1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
    "    )\n",
    "    # loss = - lagrangian (SGA)\n",
    "    # loss = - lagrangian(reconstruction_loss, kld, Lambda)\n",
    "    # calculate and apply gradient\n",
    "    # Note lambda is the trainable param here, not model params\n",
    "    # TODO: See if it's possible to include lambda in the VAE model\n",
    "    # this might make the function compilable\n",
    "    # the other option is to hard-code the SGA rather than using an optimizer\n",
    "\n",
    "    # grad = tape.gradient(target=loss, sources=[Lambda])\n",
    "    # opt = tf.keras.optimizers.Adam()\n",
    "    # opt.apply_gradients(zip(grad, [Lambda]))\n",
    "\n",
    "    Lambda = Lambda + lr * dL_dlambda(kld)\n",
    "\n",
    "    # metrics log\n",
    "    logits = {\n",
    "        # \"loss\": loss,\n",
    "        # \"reconstruction_loss\": reconstruction_loss,\n",
    "        \"kl_loss\": kld,\n",
    "        \"lambda\": Lambda,\n",
    "    }\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nTraining logs at end of warmup:\nloss 179.24568\n\nStart of epoch 1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    <ipython-input-61-60e4cba731df>:90 train_lambda_step  *\n        opt.apply_gradients(zip(grad, [Lambda]))\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:604 apply_gradients  **\n        self._create_all_weights(var_list)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:781 _create_all_weights\n        _ = self.iterations\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:788 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:921 iterations\n        self._iterations = self.add_weight(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1122 add_weight\n        variable = self._add_variable_with_custom_getter(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:805 _add_variable_with_custom_getter\n        new_variable = getter(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:130 make_variable\n        return tf_variables.VariableV1(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py:206 _variable_v1_call\n        return previous_getter(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:730 invalid_creator_scope\n        raise ValueError(\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-fef59242243c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_image_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# update lambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_lambda_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_image_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSGD_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-61-60e4cba731df>:90 train_lambda_step  *\n        opt.apply_gradients(zip(grad, [Lambda]))\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:604 apply_gradients  **\n        self._create_all_weights(var_list)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:781 _create_all_weights\n        _ = self.iterations\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:788 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:921 iterations\n        self._iterations = self.add_weight(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:1122 add_weight\n        variable = self._add_variable_with_custom_getter(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:805 _add_variable_with_custom_getter\n        new_variable = getter(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_utils.py:130 make_variable\n        return tf_variables.VariableV1(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py:206 _variable_v1_call\n        return previous_getter(\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    C:\\Users\\James\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py:730 invalid_creator_scope\n        raise ValueError(\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n"
     ]
    }
   ],
   "source": [
    "# train the VAE\n",
    "# vae_model.fit(train_images, train_images, epochs=50, batch_size=128, callbacks=[tensorboard_callback])\n",
    "\n",
    "# training loop\n",
    "warmup_iters = 100\n",
    "SGD_steps = 1\n",
    "increment_SGD_steps = 1\n",
    "epochs = 10\n",
    "Lambda = tf.Variable(0.0)\n",
    "\n",
    "for step, train_image_batch in enumerate(dataset):\n",
    "    # perform warmup\n",
    "    logits = warmup_step(train_image_batch)\n",
    "    # check if it's time to end warmup\n",
    "    # TODO: this is clumsy, try to think of another way\n",
    "    # could pre-process dataset to contain only (warmup_iters) batches\n",
    "    if step >= warmup_iters:\n",
    "        break\n",
    "\n",
    "# log after warmup\n",
    "print(\"\\nTraining logs at end of warmup:\")\n",
    "for metric, value in logits.items():\n",
    "    print(metric, value.numpy())\n",
    "\n",
    "# alternating steps\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nStart of epoch {epoch + 1}\")\n",
    "\n",
    "    # iterate over batches\n",
    "    for step, train_image_batch in enumerate(dataset):\n",
    "        # update lambda\n",
    "        logits = train_lambda_step(train_image_batch, Lambda)\n",
    "\n",
    "        for i in range(SGD_steps):\n",
    "            logits = train_w_step(train_image_batch, Lambda)\n",
    "        \n",
    "        # increment no. of steps\n",
    "        SGD_steps += increment_SGD_steps\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                f\"\\nTraining logs at step {step}:\"\n",
    "            )\n",
    "            for metric, value in logits.items():\n",
    "                print(metric, value.numpy())\n",
    "            print(\"Seen: %d samples\" % ((step + 1) * batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of encodings in the latent space\n",
    "def scatter_plot_encodings_latent(encodings, labels):\n",
    "    plt.figure(dpi=100)\n",
    "    scat = plt.scatter(encodings[:, 0], encodings[:, 1], c=labels, s=.5, cmap='Paired')\n",
    "    plt.gca().add_artist(plt.legend(*scat.legend_elements(), \n",
    "                         title='Image labels', bbox_to_anchor=(1.5, 1.)))\n",
    "    plt.xlabel('Feature X')\n",
    "    plt.ylabel('Feature Y')\n",
    "    plt.gca().set_aspect(1)\n",
    "    plt.show()\n",
    "    \n",
    "# histogram plot of encodings in the latent space\n",
    "def hist_plot_encodings_latent(encodings, labels, digit, dim, ax):\n",
    "    # extract\n",
    "    encodings_digit = encodings[labels == digit, dim]\n",
    "    # histogram\n",
    "    ax.hist(encodings_digit, bins=60, density=True, color=['g', 'b'][dim], alpha=.5)\n",
    "    # mean and std dev\n",
    "    mean = np.mean(encodings_digit)\n",
    "    std = np.std(encodings_digit)\n",
    "    ax.axvline(mean, c='r')\n",
    "    ax.set_xlabel('Digit %d, Feature %s\\n~${\\cal N}(\\mu=%.1f, \\sigma=%.1f)$' % \n",
    "                  (digit, ['X', 'Y'][dim], mean, std), c='k')\n",
    "    \n",
    "# generate images from the latent space\n",
    "def generate_images_latent(decoder, x0, x1, dx, y0, y1, dy):\n",
    "    # uniformly sample the latent space\n",
    "    nx = round((x1 - x0) / dx) + 1\n",
    "    ny = round((y1 - y0) / dy) + 1\n",
    "    grid_x = np.linspace(x0, x1, nx)\n",
    "    grid_y = np.linspace(y1, y0, ny)\n",
    "    latent = np.array(np.meshgrid(grid_x, grid_y)).reshape(2, nx * ny).T\n",
    "\n",
    "    # decode images\n",
    "    decodings = decoder.predict(latent)\n",
    "    \n",
    "    # display a (nx, ny) 2D manifold of digits\n",
    "    figure = np.zeros((28 * ny, 28 * nx))\n",
    "    for iy in np.arange(ny):\n",
    "        for ix in np.arange(nx):\n",
    "            figure[iy * 28 : (iy + 1) * 28, ix * 28 : (ix + 1) * 28] = decodings[iy * nx + ix]\n",
    "            \n",
    "    # plot figure\n",
    "    plt.figure(dpi=100, figsize=(nx / 3, ny / 3))\n",
    "    plt.xticks(np.arange(28 // 2, nx * 28 + 28 // 2, 28), np.round(grid_x, 1), rotation=90)\n",
    "    plt.yticks(np.arange(28 // 2, ny * 28 + 28 // 2, 28), np.round(grid_y, 1))\n",
    "    plt.xlabel('Feature X')\n",
    "    plt.ylabel('Feature Y')\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "# encode images by BVAE\n",
    "train_encodings_BVAE = encoder_VAE.predict(train_images)\n",
    "\n",
    "# scatter plot of encodings by BVAE\n",
    "scatter_plot_encodings_latent(train_encodings_BVAE[2], train_labels)\n",
    "\n",
    "# histogram plot of encodings by BVAE\n",
    "fig, axes = plt.subplots(5, 4, dpi=100, figsize=(15, 12), sharex=True)\n",
    "plt.subplots_adjust(hspace=.4)\n",
    "for digit in range(10):\n",
    "    hist_plot_encodings_latent(train_encodings_BVAE[2], train_labels, digit, 0, \n",
    "                               axes[digit // 2, digit % 2 * 2 + 0])\n",
    "    hist_plot_encodings_latent(train_encodings_BVAE[2], train_labels, digit, 1, \n",
    "                               axes[digit // 2, digit % 2 * 2 + 1])\n",
    "plt.show()\n",
    "\n",
    "# generate images by BVAE\n",
    "generate_images_latent(decoder_VAE, x0=-2, x1=2, dx=.1, y0=-2, y1=2, dy=.1)"
   ]
  }
 ]
}